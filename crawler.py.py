
import streamlit as st
import pandas as pd
import io
import time

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

def get_maps_data(keyword, scroll_times=30):
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    wait = WebDriverWait(driver, 10)

    driver.get("https://www.google.com/maps")
    wait.until(EC.presence_of_element_located((By.ID, "searchboxinput")))

    search_box = driver.find_element(By.ID, "searchboxinput")
    search_box.send_keys(keyword)
    wait.until(EC.element_to_be_clickable((By.ID, "searchbox-searchbutton"))).click()
    time.sleep(4)

    scrollable_div = driver.find_element(By.CSS_SELECTOR, 'div[role="main"]')

    old_count = 0
    for _ in range(scroll_times):
        driver.execute_script("arguments[0].scrollTop += arguments[0].scrollHeight", scrollable_div)
        time.sleep(1)
        results = driver.find_elements(By.CSS_SELECTOR, "div.Nv2PK")
        if len(results) == old_count:
            break
        old_count = len(results)

    results = driver.find_elements(By.CSS_SELECTOR, "div.Nv2PK")
    data = []

    for i, result in enumerate(results):
        try:
            actions = ActionChains(driver)
            actions.move_to_element(result).perform()
            result.click()
            time.sleep(1.2)  # r√∫t ng·∫Øn th·ªùi gian

            name = driver.find_element(By.CSS_SELECTOR, "h1.DUwDvf").text

            try:
                addr = driver.find_element(By.CSS_SELECTOR, 'button[data-item-id="address"]').get_attribute("aria-label").replace("ƒê·ªãa ch·ªâ: ", "")
            except:
                addr = ""

            try:
                phone = driver.find_element(By.CSS_SELECTOR, 'button[data-item-id^="phone"]').get_attribute("aria-label").replace("S·ªë ƒëi·ªán tho·∫°i: ", "")
            except:
                phone = ""

            if not phone:
                driver.back()
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.Nv2PK")))
                results = driver.find_elements(By.CSS_SELECTOR, "div.Nv2PK")
                continue

            try:
                open_hours = driver.find_element(By.CSS_SELECTOR, 'div[aria-label*="Th·ª© Hai"]').get_attribute("aria-label")
            except:
                open_hours = ""

            try:
                website = driver.find_element(By.CSS_SELECTOR, 'a[data-item-id="authority"]').get_attribute("href")
            except:
                website = ""

            gmail = ""
            try:
                desc_divs = driver.find_elements(By.CSS_SELECTOR, "div[jsaction*='pane']")
                for div in desc_divs:
                    text = div.text
                    if "@gmail.com" in text:
                        gmail = [w for w in text.split() if "@gmail.com" in w][0]
                        break
            except:
                gmail = ""

            data.append({
                "T·ª´ kh√≥a": keyword,
                "T√™n": name,
                "ƒê·ªãa ch·ªâ": addr,
                "S·ªë ƒëi·ªán tho·∫°i": phone,
                "Gi·ªù m·ªü c·ª≠a": open_hours,
                "Website": website,
                "Gmail": gmail
            })

            driver.back()
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.Nv2PK")))
            results = driver.find_elements(By.CSS_SELECTOR, "div.Nv2PK")

        except Exception as e:
            continue

    driver.quit()
    return pd.DataFrame(data)

# Giao di·ªán Streamlit
st.set_page_config(page_title="Google Maps Scraper N√¢ng c·∫•p", layout="wide")
st.title("üìç Google Maps Scraper Pro (Nhanh + Th√¥ng minh)")

keywords_input = st.text_area("üîç Nh·∫≠p nhi·ªÅu t·ª´ kh√≥a t√¨m ki·∫øm (m·ªói d√≤ng 1 t·ª´ kh√≥a)")
scroll_times = st.slider("üîÅ T·ªëi ƒëa s·ªë l·∫ßn cu·ªôn Google Maps", min_value=5, max_value=50, value=20)

if st.button("üöÄ B·∫Øt ƒë·∫ßu t√¨m ki·∫øm"):
    if not keywords_input.strip():
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p √≠t nh·∫•t m·ªôt t·ª´ kh√≥a.")
    else:
        all_data = pd.DataFrame()
        keyword_list = [kw.strip() for kw in keywords_input.strip().split("\n") if kw.strip()]

        with st.spinner("‚è≥ ƒêang t√¨m ki·∫øm v√† tr√≠ch xu·∫•t d·ªØ li·ªáu..."):
            for kw in keyword_list:
                st.info(f"üîé ƒêang t√¨m: {kw}")
                df = get_maps_data(kw, scroll_times)
                all_data = pd.concat([all_data, df], ignore_index=True)

        st.success(f"üéâ ƒê√£ t√¨m th·∫•y {len(all_data)} k·∫øt qu·∫£ c√≥ s·ªë ƒëi·ªán tho·∫°i!")

        if not all_data.empty:
            st.dataframe(all_data)

            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                all_data.to_excel(writer, index=False)
            processed_data = output.getvalue()

            st.download_button(
                label="‚¨áÔ∏è T·∫£i k·∫øt qu·∫£ Excel",
                data=processed_data,
                file_name="ket_qua_maps_nhanh.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
